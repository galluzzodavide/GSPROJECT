{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22a65b0e",
   "metadata": {},
   "source": [
    "The Decoder module generates local high-resolution forecast maps (1 km resolution) from the\n",
    "coarse predictions. Even if the ConvLSTM/Processor operates on a lower-resolution grid (for\n",
    "computational efficiency or due to patch embedding), the Decoder will upsample and refine the output.\n",
    "\n",
    "U-Net architecture, a well-known convolutional network with an encoder-decoder structure and skip connections that preserve fine details . The U-Net takes as input the coarse forecast (e.g. a 2D field at, say, 10 km resolution) and outputs a finer 1 km grid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab77bd11",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------------------\n",
    "this acts as a super\n",
    "resolution or downscaling model, adding local detail (potentially informed by high-res static data like\n",
    " topography or coastline, if we include those as additional inputs).\n",
    "\n",
    "Our U-Net Decoder operates per forecast time step (it processes one frame at a time, independently,\n",
    " since spatial super-resolution can be learned time-independently). We design the U-Net with a\n",
    " contracting path that reduces the spatial dimension and an expanding path that increases it back, with\n",
    " skip connections from contracting to expanding path to preserve high-frequency information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1753c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetDecoder(nn.Module):\n",
    "def __init__(self, in_channels, out_channels, base_channels=64):\n",
    "    super().__init__()\n",
    "    \n",
    "    # Contracting path\n",
    "    self.enc1 = nn.Sequential(\n",
    "    nn.Conv2d(in_channels, base_channels, 3, padding=1), nn.ReLU(),\n",
    "    nn.Conv2d(base_channels, base_channels, 3, padding=1), nn.ReLU())\n",
    "    self.pool1 = nn.MaxPool2d(2)\n",
    "    self.enc2 = nn.Sequential(\n",
    "    nn.Conv2d(base_channels, base_channels*2, 3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(base_channels*2, base_channels*2, 3, padding=1),\n",
    "    nn.ReLU())\n",
    "    self.pool2 = nn.MaxPool2d(2)\n",
    "    self.enc3 = nn.Sequential(\n",
    "    nn.Conv2d(base_channels*2, base_channels*4, 3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(base_channels*4, base_channels*4, 3, padding=1),\n",
    "    nn.ReLU())\n",
    "    \n",
    "    # Expanding path\n",
    "    self.up2 = nn.ConvTranspose2d(base_channels*4, base_channels*2, kernel_size=2, stride=2)\n",
    "    self.dec2 = nn.Sequential(\n",
    "    nn.Conv2d(base_channels*4, base_channels*2, 3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(base_channels*2, base_channels*2, 3, padding=1),\n",
    "    nn.ReLU())\n",
    "    self.up1 = nn.ConvTranspose2d(base_channels*2, base_channels, kernel_size=2, stride=2)\n",
    "    self.dec1 = nn.Sequential(nn.Conv2d(base_channels*2, base_channels, 3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(base_channels, base_channels, 3, padding=1), nn.ReLU())\n",
    "    self.final = nn.Conv2d(base_channels, out_channels, kernel_size=1)\n",
    " def forward(self, x):\n",
    "    \n",
    "    # x: (B, in_channels, H_coarse, W_coarse)\n",
    "    e1 = self.enc1(x) # (B, 64, H, W)\n",
    "    p1 = self.pool1(e1) # (B, 64, H/2, W/2)\n",
    "    e2 = self.enc2(p1) # (B, 128, H/2, W/2)\n",
    "    p2 = self.pool2(e2) # (B, 128, H/4, W/4)\n",
    "    e3 = self.enc3(p2) # (B, 256, H/4, W/4)\n",
    "    \n",
    "    # Decoder\n",
    "    u2 = self.up2(e3) # (B, 128, H/2, W/2)\n",
    "    u2 = torch.cat([u2, e2], dim=1) # skip connection concatenation\n",
    "    d2 = self.dec2(u2) # (B, 128, H/2, W/2)\n",
    "    u1 = self.up1(d2) # (B, 64, H, W)\n",
    "    u1 = torch.cat([u1, e1], dim=1) # concat skip from e1\n",
    "    d1 = self.dec1(u1) # (B, 64, H, W)\n",
    "    out = self.final(d1)\n",
    "    return out\n",
    "# (B, out_channels, H, W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d62ad6e",
   "metadata": {},
   "source": [
    " We integrate Encoder, Processor, and Decoder into one end-to-end model, which weâ€™ll call\n",
    " WeatherForecastNet . During training, the dataflow is:\n",
    " 1. \n",
    "2. \n",
    "3. \n",
    "4. \n",
    "Input: A sequence of past observations (or just the current state) on the common grid. For\n",
    " example, we might use the last 3 hourly grids as input to provide the model some notion of\n",
    " recent motion, although the problem statement focuses on assimilating current data.\n",
    " Encoder: Produces encoded features (global and/or spatial) from the input.\n",
    " Processor: Generates a sequence of coarse future predictions (up to 48 frames for 48 hours).\n",
    " Decoder: Upscales each coarse frame to high resolution.\n",
    " We train the model in a supervised manner using historical data. We need training pairs of (input data,\n",
    " ground-truth future data). Ground truth could come from reanalysis (like ERA5) or from the actual\n",
    " observations at +hours (for example, satellite images at future times, buoy readings at future times,\n",
    " etc., interpolated to the grid)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d3deef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
